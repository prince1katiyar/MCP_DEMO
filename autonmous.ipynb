{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# playwright_agent_demo_jupyter.py (multi-step automation with Playwright for Jupyter)\n",
    "\n",
    "# âœ… Required installations (run in a notebook cell):\n",
    "# !pip install playwright nest_asyncio\n",
    "# !playwright install\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "nest_asyncio.apply()  # Allows running async loops in notebooks\n",
    "\n",
    "INSTRUCTIONS = [\n",
    "    {\n",
    "        \"description\": \"Go to Hacker News\",\n",
    "        \"url\": \"https://news.ycombinator.com/\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Click the top news article (fallback safe)\",\n",
    "        \"fallback\": \"a.titleline a\",\n",
    "        \"selector\": \"a.storylink, a.titlelink, a.titleline a\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Return to Hacker News homepage\",\n",
    "        \"url\": \"https://news.ycombinator.com/\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Click 'new' link to see recent posts\",\n",
    "        \"selector\": \"a[href='newest']\"\n",
    "    }\n",
    "]\n",
    "\n",
    "async def run_playwright_steps_async():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        for step in INSTRUCTIONS:\n",
    "            print(f\"ðŸ”¹ {step['description']}\")\n",
    "            if \"url\" in step:\n",
    "                try:\n",
    "                    await page.goto(step[\"url\"], timeout=60000)\n",
    "                    await page.wait_for_load_state(\"domcontentloaded\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Failed to load URL: {step['url']}\\n{e}\")\n",
    "                    continue\n",
    "            elif \"selector\" in step:\n",
    "                try:\n",
    "                    await page.wait_for_selector(step[\"selector\"], timeout=10000)\n",
    "                    element = page.locator(step[\"selector\"])\n",
    "                    if await element.count() > 0:\n",
    "                        await element.first.click()\n",
    "                        await asyncio.sleep(2)\n",
    "                    else:\n",
    "                        print(\"âš ï¸ Element not found â€” trying fallback selector\")\n",
    "                        if \"fallback\" in step:\n",
    "                            try:\n",
    "                                await page.wait_for_selector(step[\"fallback\"], timeout=5000)\n",
    "                                element = page.locator(step[\"fallback\"])\n",
    "                                await element.first.click()\n",
    "                            except:\n",
    "                                print(\"âŒ Fallback also failed\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Failed at selector: {step['selector']}\\n{e}\")\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "        print(\"âœ… All steps completed\")\n",
    "        await browser.close()\n",
    "\n",
    "# âœ… To run in a Jupyter notebook cell:\n",
    "# await run_playwright_steps_async()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Go to Hacker News\n",
      "ðŸ”¹ Click the top news article (fallback safe)\n",
      "âŒ Failed at selector: a.storylink, a.titlelink, a.titleline a\n",
      "Page.wait_for_selector: Timeout 10000ms exceeded.\n",
      "Call log:\n",
      "  - waiting for locator(\"a.storylink, a.titlelink, a.titleline a\") to be visible\n",
      "\n",
      "ðŸ”¹ Return to Hacker News homepage\n",
      "ðŸ”¹ Click 'new' link to see recent posts\n",
      "âœ… All steps completed\n"
     ]
    }
   ],
   "source": [
    "await run_playwright_steps_async()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Function must have a docstring if description not provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     latitude: \u001b[38;5;28mfloat\u001b[39m = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33mLatitude of the location\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m     longitude: \u001b[38;5;28mfloat\u001b[39m = Field(..., description=\u001b[33m\"\u001b[39m\u001b[33mLongitude of the location\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;129;43m@tool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOpenMeteoInput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mget_current_temperature\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://api.open-meteo.com/v1/forecast\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlongitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhourly\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature_2m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforecast_days\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI_projects/mcp demo/.venv/lib/python3.11/site-packages/langchain_core/tools/convert.py:346\u001b[39m, in \u001b[36mtool.<locals>._partial\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m    344\u001b[39m name_ = func.get_name() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, Runnable) \u001b[38;5;28;01melse\u001b[39;00m func.\u001b[34m__name__\u001b[39m\n\u001b[32m    345\u001b[39m tool_factory = _create_tool_factory(name_)\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtool_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI_projects/mcp demo/.venv/lib/python3.11/site-packages/langchain_core/tools/convert.py:264\u001b[39m, in \u001b[36mtool.<locals>._create_tool_factory.<locals>._tool_factory\u001b[39m\u001b[34m(dec_func)\u001b[39m\n\u001b[32m    261\u001b[39m     schema = args_schema\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m infer_schema \u001b[38;5;129;01mor\u001b[39;00m args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStructuredTool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoroutine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_direct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_schema\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_docstring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_on_invalid_docstring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# If someone doesn't want a schema applied, we must treat it as\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# a simple string->string function\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dec_func.\u001b[34m__doc__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI_projects/mcp demo/.venv/lib/python3.11/site-packages/langchain_core/tools/structured.py:211\u001b[39m, in \u001b[36mStructuredTool.from_function\u001b[39m\u001b[34m(cls, func, coroutine, name, description, return_direct, args_schema, infer_schema, response_format, parse_docstring, error_on_invalid_docstring, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m description_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    210\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mFunction must have a docstring if description not provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m description \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# Only apply if using the function's docstring\u001b[39;00m\n\u001b[32m    214\u001b[39m     description_ = textwrap.dedent(description_).strip()\n",
      "\u001b[31mValueError\u001b[39m: Function must have a docstring if description not provided."
     ]
    }
   ],
   "source": [
    "# conversational_agent_app.py - Build a full LangChain-powered conversational agent with tools and memory\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import datetime\n",
    "import requests\n",
    "import wikipedia\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.tools import tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor\n",
    "import panel as pn\n",
    "import param\n",
    "\n",
    "# Load API Key\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# ========== Define Tools ==========\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> str:\n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    params = {\"latitude\": latitude, \"longitude\": longitude, \"hourly\": \"temperature_2m\", \"forecast_days\": 1}\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code != 200:\n",
    "        return \"Weather API failed.\"\n",
    "    data = response.json()\n",
    "    now = datetime.datetime.utcnow()\n",
    "    times = [datetime.datetime.fromisoformat(t.replace(\"Z\", \"+00:00\")) for t in data['hourly']['time']]\n",
    "    temps = data['hourly']['temperature_2m']\n",
    "    index = min(range(len(times)), key=lambda i: abs(times[i] - now))\n",
    "    return f\"The current temperature is {temps[index]}Â°C\"\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for title in titles[:3]:\n",
    "        try:\n",
    "            page = wikipedia.page(title, auto_suggest=False)\n",
    "            summaries.append(f\"**{title}**\\n{page.summary}\")\n",
    "        except:\n",
    "            pass\n",
    "    return \"\\n\\n\".join(summaries) if summaries else \"No good result found.\"\n",
    "\n",
    "@tool\n",
    "def create_your_own(query: str) -> str:\n",
    "    return f\"You sent: {query}. This reverses it: {query[::-1]}\"\n",
    "\n",
    "# ========== Register Tools ==========\n",
    "tools = [get_current_temperature, search_wikipedia, create_your_own]\n",
    "\n",
    "# ========== Panel Chatbot UI ==========\n",
    "pn.extension()\n",
    "\n",
    "class ConversationalBot(param.Parameterized):\n",
    "    def __init__(self, tools, **params):\n",
    "        super().__init__(**params)\n",
    "        self.panels = []\n",
    "        self.tool_funcs = [format_tool_to_openai_function(t) for t in tools]\n",
    "        self.llm = ChatOpenAI(temperature=0).bind(functions=self.tool_funcs)\n",
    "        self.memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are helpful but sassy assistant.\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"user\", \"{input}\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "        ])\n",
    "\n",
    "        self.chain = RunnablePassthrough.assign(\n",
    "            agent_scratchpad=lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "        ) | self.prompt | self.llm | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "        self.executor = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n",
    "\n",
    "    def interact(self, query):\n",
    "        if not query:\n",
    "            return\n",
    "        result = self.executor.invoke({\"input\": query})\n",
    "        self.answer = result['output']\n",
    "        self.panels.extend([\n",
    "            pn.Row('User:', pn.pane.Markdown(query, width=500)),\n",
    "            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=500, styles={\"background-color\": \"#f0f0f0\"}))\n",
    "        ])\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "# ========== Launch the Panel Chat App ==========\n",
    "cb = ConversationalBot(tools)\n",
    "inp = pn.widgets.TextInput(placeholder='Ask me anything...')\n",
    "conversation = pn.bind(cb.interact, inp)\n",
    "\n",
    "tab = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation, loading_indicator=True, height=400),\n",
    "    pn.layout.Divider()\n",
    ")\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown('# ðŸ§  Conversational Agent Bot')),\n",
    "    pn.Tabs(('Chat', tab))\n",
    ")\n",
    "\n",
    "dashboard.servable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting panel\n",
      "  Downloading panel-1.6.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting param\n",
      "  Downloading param-2.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.75.0)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.11/site-packages (0.3.23)\n",
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (2.32.3)\n",
      "Collecting bleach (from panel)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting bokeh<3.8.0,>=3.5.0 (from panel)\n",
      "  Downloading bokeh-3.7.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting linkify-it-py (from panel)\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting markdown (from panel)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting markdown-it-py (from panel)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdit-py-plugins (from panel)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from panel) (24.2)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.11/site-packages (from panel) (2.2.3)\n",
      "Collecting pyviz-comms>=2.0.0 (from panel)\n",
      "  Downloading pyviz_comms-3.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from panel) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from panel) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in ./.venv/lib/python3.11/site-packages (from langchain) (0.3.54)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./.venv/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain) (0.3.32)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting beautifulsoup4 (from wikipedia)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests) (2025.1.31)\n",
      "Collecting Jinja2>=2.9 (from bokeh<3.8.0,>=3.5.0->panel)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting contourpy>=1.2 (from bokeh<3.8.0,>=3.5.0->panel)\n",
      "  Using cached contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting narwhals>=1.13 (from bokeh<3.8.0,>=3.5.0->panel)\n",
      "  Using cached narwhals-1.35.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in ./.venv/lib/python3.11/site-packages (from bokeh<3.8.0,>=3.5.0->panel) (2.2.4)\n",
      "Requirement already satisfied: pillow>=7.1.0 in ./.venv/lib/python3.11/site-packages (from bokeh<3.8.0,>=3.5.0->panel) (11.2.1)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv/lib/python3.11/site-packages (from bokeh<3.8.0,>=3.5.0->panel) (6.4.2)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh<3.8.0,>=3.5.0->panel)\n",
      "  Downloading xyzservices-2025.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->panel) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->panel) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->panel) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->wikipedia)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting webencodings (from bleach->panel)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py->panel)\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py->panel)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=2.9->bokeh<3.8.0,>=3.5.0->panel)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->panel) (1.17.0)\n",
      "Downloading panel-1.6.2-py3-none-any.whl (28.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading param-2.2.0-py3-none-any.whl (119 kB)\n",
      "Downloading bokeh-3.7.2-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyviz_comms-3.0.4-py3-none-any.whl (83 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Using cached contourpy-1.3.2-cp311-cp311-macosx_11_0_arm64.whl (254 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached narwhals-1.35.0-py3-none-any.whl (325 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading xyzservices-2025.1.0-py3-none-any.whl (88 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: webencodings, xyzservices, uc-micro-py, soupsieve, param, narwhals, mdurl, MarkupSafe, markdown, contourpy, bleach, pyviz-comms, markdown-it-py, linkify-it-py, Jinja2, beautifulsoup4, wikipedia, mdit-py-plugins, bokeh, panel\n",
      "Successfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 beautifulsoup4-4.13.4 bleach-6.2.0 bokeh-3.7.2 contourpy-1.3.2 linkify-it-py-2.0.3 markdown-3.8 markdown-it-py-3.0.0 mdit-py-plugins-0.4.2 mdurl-0.1.2 narwhals-1.35.0 panel-1.6.2 param-2.2.0 pyviz-comms-3.0.4 soupsieve-2.7 uc-micro-py-1.0.3 webencodings-0.5.1 wikipedia-1.4.0 xyzservices-2025.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install panel param openai langchain wikipedia python-dotenv requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
